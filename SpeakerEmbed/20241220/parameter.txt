accumulation_stepを128で実行
# setting
epochs = 30000
test_rate = 0.2
batch_size = 97
accumulation_step = 128
model_type = 'conv1'
input_type = ['msp']
t = 1.0 # 温度係数
eps = 1e-5

in_channels = 1
hidden_channels = 256

# enc
frame_length = 22
in_channels = 80
hidden_channels = 256
inter_channels = 192
encoder_dwn_kernel_size=5
dilation_rate = 2
n_layers = 16

# optimizer
adam

# 特徴ベクトル計算
v_f = torch.mean(v_f, dim=(2))
w_f = torch.mean(w_f, dim=(2))
vf_l2 = torch.sqrt((v_f**2).sum(dim=1))
v_f = (v_f.T/(vf_l2+eps)).T
wf_l2 = torch.sqrt((w_f**2).sum(dim=1))
w_f = (w_f.T/(wf_l2+eps)).T

# 類似度計算
logits = torch.matmul(v_f, w_f.T) * torch.exp(torch.tensor(t))
labels = torch.arange(0, v.size(0), dtype=torch.long, device=device)
entropy_loss = (criterion_crossentropy(logits, labels) + criterion_crossentropy(logits.T, labels)) / 2
loss = (entropy_loss) / accumulation_step